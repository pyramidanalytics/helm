repo: "pyramidanalytics"
imagePullPolicy: "IfNotPresent"
#unattended is all optional, if not enabled you will get a UI on first load letting you configure it all
unattended:
  enabled: false
  # Set the following field to the equivalent of the unattended json as defined in the pyramid help
  # under the "Kubernetes Unattended Initialization" section.
  installationData:
    # The type of pyramid database used for installation.
    # If provided as "existing" - the database server should contain an existing (previously installed) Pyramid database.
    # If provided as "new", a new pyramid database schema will be created in the provided database.
    installationType: "new"
    # 0 - Native installation - self provided database server
    # 1 - AWS RDS
    # 2 - Azure Managed Database
    # 3 - GCP Cloud SQL
    dbLocation: 0
    # The type of database server into which the pyramid database is installed.
    # "SqlServer" - Microsoft SQL Server
    # "Postgresql" - PostgreSQL
    serverType: "Postgresql"
    # The address of the database server - IP or hostname
    serverAddress: "ip-or-fqdn"
    # The port of the database server
    port: 5432
    # If provided as "on", the installer will connect to the database with the provided credentials,
    # and will attempt to create the database.
    # Providing "on" is not applicable when "existing" or "rds" is provided for the repoType field.
    createDB: "on"
    # The name of the database to create
    database: "pyramid"
    # The username for the database user authentication
    dbUser: "postgres"
    # The database user's password
    dbPass: "<password>"
    # Specify "on" for enforcing ssl over the database connection, or "off" otherwise.
    enforceDbSsl: "off"
    #When using encrypted database, you can upload your own Certificate using this field, it's optional, base64 encoded zip file
    dbSslRootCert: ""
    #Use fips compatible encryption algorithms, this will disable some of the product functionality
    fips: false
    # The name of the initial (admin) user created in the pyramid system
    firstUser: "admin"
    # The password to use for the initial user
    firstUserPass: "<password>"
    # The type of the storage to use for the pyramid filesystem repository
    # Applicable values are:
    # "PersistentVolume" - Kubernetes managed persistent volume
    # "AWSS3" - AWS S3 Bucket
    # "AzureBlob" - Azure Blob Storage
    # "FTP" - FTP based storage
    # "SFTP" - SSH File Transfer Protocol Storage
    # "NFS" - Mounted File System
    storageType: "PersistentVolume"

    # If storageType is "FTP"/"SFTP" - specify the IP/hostname of the storage server
    storageHostName: "ip-or-fqdn"
    # If storageType is "FTP"/"SFTP" - specify the port of the storage server
    storagePort: 0
    # If storageType is "FTP"/"SFTP" - specify the username of the storage
    storageUserName: "storageUser"
    # If storageType is "FTP"/"SFTP" - specify the password of the storage
    storagePassword: "storagePassword"
    # If storageType is "FTP"/"SFTP"/"NFS" - specify the path to the storage folder
    storageFolder: "/path/to/storage/directory"

    # If storageType is "AWSS3" - Specify the region id of the S3 Bucket
    regionId: "eu-central-1"
    # If storageType is "AWSS3" - Specify the access Key id for the S3 Bucket, or "iam" to use IAM role
    # To use an AWS IAM role, set awsAccessKeyId: "iam" after configuring a role on AWS. In this case you do not need to set awsSecretAccessKey.
    awsAccessKeyId: "awsAccessKeyId"
    # If storageType is "AWSS3" - Specify the secret key for the S3 bucket
    awsSecretAccessKey: "awsSecretAccessKey"
    # If storageType is "AWSS3" - Specify the name of the S3 bucket
    awsBucket: "bucket-name"

    # If storageType is "AzureBlob" - Specify the account name of the azure blob
    azureBlobAccountName: "accountName"
    # If storageType is "AzureBlob" - Specify the account key of the azure blob
    azureBlobAccountKey: "accountKey"
    # If storageType is "AzureBlob" - Specify the account container of the azure blob
    azureContainer: "container"
    # The text content of the pyramid license. Can be used to initialize the system with a license.
    # If the field is not specified, the license can instead be uploaded to the system after installation.
    license: "licenseTextContent"

# Persistent storage configured for applicable pods.
storage:
  # Type of persistent storage.
  # Applicable values are: GoogleStore, NFS, other
  # GoogleStore/NFS - define a PersistentVolume resource.
  # other - Defines external storage options (such as FTP/AWS S3/Azure Blob), which are configured via the WEB UI installation or the unattended installation.
  type: other
  # When type is set to GoogleStore/NFS: specify the size of the PersistentVolume and the relevant section
  size: "10Gi"
  # When type is set to NFS, update the following section.
  nfs:
    # The path the storage folder on the NFS server
    path: "/"
    # The address of the NFS server
    ip: "0.0.0.0"
  
  # GoogleStore is file store on GCP,  update the following section.
  GoogleStore:
    #This parameter specifies the VPC network that the Filestore instance will be created on.
    network: default
#ws is the web server which handle http networking and authentication
ws:
  #defult port for your ws, match this with your ingress
  port: 8181
  #how many ws would you want
  replicas: 1
  requests:
    #minimal amount of memory guaranteed, you can add here but don't reduce
    memory: "2000Mi"
    cpu: "2000m"
    ephemeral_storage: "2Gi"
  limits:
    #you can increase those values to better match your nodes, the WS main limitation is IO
    memory: "2000Mi"
    cpu: "16000m"
    ephemeral_storage: "4Gi"

  kedaAutoscaling:
    #if enabled will use Keda to auto-scale based on active requests
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    # An average number of requests per web server before scaling
    threshold: 180

#rtr router is the core of request routing, deciding where to send the request
rtr:
  #how many routers you want, 1 is fine for performance, 2 will increase reliability, 3 and more are meaningless
  replicas: 1
  requests:
    #minimal amount of memory guaranteed, you can add here but don't reduce
    memory: "1000Mi"
    cpu: "1000m"
  limits:
  #you can increase those values to better match your nodes, but normally there shouldn't be a need for it
    memory: "1000Mi"
    cpu: "4000m"

#rte is the runtime engine, the core of the application which handles all active requests, queries and CMS
rte:
  requests:
    #minimal amount of memory guaranteed, you can add here but don't reduce
    memory: "4000Mi"
    cpu: "2000m"
  limits:
  #you can increase those values to better match your nodes, based on system usage the RTE can be very cpu heavy
    memory: "8000Mi"
    cpu: "8000m"
  #how many replicates do you want, the system will do it's best to use all of them equally 
  replicas: 1
  #satellties are used to preview ETL results
  satellites: 1
  #in the event of a high cpu usage the autoscale will add another RTE server
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    # Average cpu usage (percentage) across all RTE pods before scaling
    targetCpuUtilization: 70
    # Average memory usage (percentage) across all RTE pods before scaling
    targetMemoryUtilization: 75

#nlp is the nlp engine, the service responsible for the chatbot function in the discover app
nlp:
  requests:
    #minimal amount of memory guaranteed, you can add here but don't reduce
    memory: "4000Mi"
    cpu: "2000m"
  limits:
    #you can increase those values to better match your nodes, based on system usage the nlp can be very cpu heavy
    memory: "8000Mi"
    cpu: "4000m"
  #how many replicates do you want, the system will do it's best to use all of them equally
  replicas: 1
  #in the event of a high cpu usage the autoscale will add another nlp server
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetCpuUtilization: 70
    targetMemoryUtilization: 75

#solve is the solver engine, a service which runs the solve requests
solve:
  requests:
    #minimal amount of memory guaranteed, you can add here but don't reduce
    memory: "4000Mi"
    cpu: "2000m"
  limits:
    #you can increase those values to better match your nodes, based on system usage the solve can be very cpu heavy
    memory: "8000Mi"
    cpu: "4000m"
  #how many replicates do you want, the system will do it's best to use all of them equally 
  replicas: 1
  #in the event of a high cpu usage the autoscaler will add another solve server
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetCpuUtilization: 70
    targetMemoryUtilization: 75

#te is the Task engine, handles ETLs and prints
te:
  requests:
    #minimal amount of memory guaranteed, you can add here but don't reduce
    memory: "4000Mi"
    cpu: "4000m"
    ephemeral_storage: "3Gi"
  limits:
  #you can increase those values to better match your nodes, based on system usage the TE can be CPU heavy and memory heavy
    memory: "16000Mi"
    cpu: "16000m"
    ephemeral_storage: "10Gi"
  # After the first termination message is sent to pod, it is given this amount of time in seconds before it's forcefully deleted
  terminationGracePeriodSeconds: 300
  replicas: 1
  #satellites are used to run ETL tasks
  satellites: 3
  #printers are used to export printing result to PDF, Power Point, Word, excel, HTML to and a few
  printers: 3

  #in the event of a long queue in the task engine the autoscale will add another TE server
  kedaAutoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
#ai is the artificial intelligence server which host all Python and R script handling
ai:
  requests:
    #minimal amount of memory guaranteed, you can add here but don't reduce
    memory: "4000Mi"
    cpu: "4000m"
    ephemeral_storage: "3Gi"
  limits:
  #you can increase those values to better match your nodes, based on system usage the AI can be very cpu heavy
    memory: "16000Mi"
    cpu: "16000m"
    ephemeral_storage: "5Gi"
  replicas: 1
  #full flag makes the system use AIF Docker image with pre-installed Python libraries, designed for offline use.
  full: false
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetCpuUtilization: 70
    targetMemoryUtilization: 75
#GIS is the GeoSpatial server handles mapping data for queris, can be disabled if not in use
#supports only 1 replica
gis:
  enabled: true
  requests:
    #minimal amount of memory guaranteed, you can add here but don't reduce
    memory: "500Mi"
    cpu: "500m"
  limits:
    #you can increase those values to better match your nodes, but normally there shouldn't be a need for it
    memory: "1500Mi"
    cpu: "1500m"
